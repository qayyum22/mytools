[
  {
    "title": "TensorFlow.js Node API",
    "url": "https://js.tensorflow.org/api_node/4.20.0/",
    "html": "menu\nOverview API Reference Node API tfjs-vis API tfjs-react-native API tfjs-tflite API Task API\nTensorFlow.js\nOverview\nTutorials & Guides\nAPI Reference\nNode API\ntfjs-vis API\nGitHub\nAPI Version\n4.20.0\nTENSORBOARD\ntf.node.summaryFileWriter\ntf.node.tensorBoard\nOPERATIONS\nImages\ntf.node.decodeBmp\ntf.node.decodeGif\ntf.node.decodeImage\ntf.node.decodeJpeg\ntf.node.decodePng\ntf.node.encodeJpeg\ntf.node.encodePng\nMODELS\nSavedModel\ntf.node.TFSavedModel\n.dispose\n.predict\n.execute\ntf.node.getMetaGraphsFromSavedModel\ntf.node.loadSavedModel\nTensorBoard\n\nFunctions for visualizing training in TensorBoard\n\nTensorBoard /\ntf.node.summaryFileWriter (logdir, maxQueue?, flushMillis?, filenameSuffix?) function\nsource\n\nCreate a summary file writer for TensorBoard.\n\nExample:\n\nconst tf = require('@tensorflow/tfjs-node');\n\nconst summaryWriter = tf.node.summaryFileWriter('/tmp/tfjs_tb_logdir');\n\nfor (let step = 0; step < 100; ++step) {\n  summaryWriter.scalar('dummyValue', Math.sin(2 * Math.PI * step / 8), step);\n}\n\nParameters:\nlogdir (string) Log directory in which the summary data will be written.\nmaxQueue (number) Maximum queue length (default: 10). Optional\nflushMillis (number) Flush every __ milliseconds (default: 120e3, i.e, 120 seconds). Optional\nfilenameSuffix (string) Suffix of the protocol buffer file names to be written in the logdir (default: .v2). Optional\nReturns: SummaryFileWriter\ntf.node.tensorBoard (logdir?, args?) function\nsource\n\nCallback for logging to TensorBoard during training.\n\nWrites the loss and metric values (if any) to the specified log directory (logdir) which can be ingested and visualized by TensorBoard. This callback is usually passed as a callback to tf.Model.fit() or tf.Model.fitDataset() calls during model training. The frequency at which the values are logged can be controlled with the updateFreq field of the configuration object (2nd argument).\n\nUsage example:\n\n// Constructor a toy multilayer-perceptron regressor for demo purpose.\nconst model = tf.sequential();\nmodel.add(\n     tf.layers.dense({units: 100, activation: 'relu', inputShape: [200]}));\nmodel.add(tf.layers.dense({units: 1}));\nmodel.compile({\n   loss: 'meanSquaredError',\n   optimizer: 'sgd',\n   metrics: ['MAE']\n});\n\n// Generate some random fake data for demo purpose.\nconst xs = tf.randomUniform([10000, 200]);\nconst ys = tf.randomUniform([10000, 1]);\nconst valXs = tf.randomUniform([1000, 200]);\nconst valYs = tf.randomUniform([1000, 1]);\n\n// Start model training process.\nawait model.fit(xs, ys, {\n   epochs: 100,\n   validationData: [valXs, valYs],\n    // Add the tensorBoard callback here.\n   callbacks: tf.node.tensorBoard('/tmp/fit_logs_1')\n});\n\n\nThen you can use the following commands to point tensorboard to the logdir:\n\npip install tensorboard  # Unless you've already installed it.\ntensorboard --logdir /tmp/fit_logs_1\n\nParameters:\nlogdir (string) Directory to which the logs will be written. Optional\nargs (Object) Optional configuration arguments. Optional\nupdateFreq ('batch'|'epoch') The frequency at which loss and metric values are written to logs.\n\nCurrently supported options are:\n\n'batch': Write logs at the end of every batch of training, in addition to the end of every epoch of training.\n'epoch': Write logs at the end of every epoch of training.\n\nNote that writing logs too often slows down the training.\n\nDefault: 'epoch'.\n\nhistogramFreq (number) The frequency (in epochs) at which to compute activation and weight histograms for the layers of the model.\n\nIf set to 0, histograms won't be computed.\n\nValidation data (or split) must be specified for histogram visualizations.\n\nDefault: 0.\n\nReturns: TensorBoardCallback\nOperations\nOperations / Images\ntf.node.decodeBmp (contents, channels?) function\nsource\n\nDecode the first frame of a BMP-encoded image to a 3D Tensor of dtype int32.\n\nParameters:\ncontents (Uint8Array) The BMP-encoded image in an Uint8Array.\nchannels (number) An optional int. Defaults to 0. Accepted values are 0: use the number of channels in the BMP-encoded image. 3: output an RGB image. 4: output an RGBA image. Optional\nReturns: Tensor3D\ntf.node.decodeGif (contents) function\nsource\n\nDecode the frame(s) of a GIF-encoded image to a 4D Tensor of dtype int32.\n\nParameters:\ncontents (Uint8Array) The GIF-encoded image in an Uint8Array.\nReturns: Tensor4D\ntf.node.decodeImage (content, channels?, dtype?, expandAnimations?) function\nsource\n\nGiven the encoded bytes of an image, it returns a 3D or 4D tensor of the decoded image. Supports BMP, GIF, JPEG and PNG formats.\n\nParameters:\ncontent (Uint8Array) The encoded image in an Uint8Array.\nchannels (number) An optional int. Defaults to 0, use the number of channels in the image. Number of color channels for the decoded image. It is used when image is type Png, Bmp, or Jpeg. Optional\ndtype (string) The data type of the result. Only int32 is supported at this time. Optional\nexpandAnimations (boolean) A boolean which controls the shape of the returned op's output. If True, the returned op will produce a 3-D tensor for PNG, JPEG, and BMP files; and a 4-D tensor for all GIFs, whether animated or not. If, False, the returned op will produce a 3-D tensor for all file types and will truncate animated GIFs to the first frame. Optional\nReturns: Tensor3D|Tensor4D\ntf.node.decodeJpeg (contents, channels?, ratio?, fancyUpscaling?, tryRecoverTruncated?, acceptableFraction?, dctMethod?) function\nsource\n\nDecode a JPEG-encoded image to a 3D Tensor of dtype int32.\n\nParameters:\ncontents (Uint8Array) The JPEG-encoded image in an Uint8Array.\nchannels (number) An optional int. Defaults to 0. Accepted values are 0: use the number of channels in the JPEG-encoded image. 1: output a grayscale image. 3: output an RGB image. Optional\nratio (number) An optional int. Defaults to 1. Downscaling ratio. It is used when image is type Jpeg. Optional\nfancyUpscaling (boolean) An optional bool. Defaults to True. If true use a slower but nicer upscaling of the chroma planes. It is used when image is type Jpeg. Optional\ntryRecoverTruncated (boolean) An optional bool. Defaults to False. If true try to recover an image from truncated input. It is used when image is type Jpeg. Optional\nacceptableFraction (number) An optional float. Defaults to 1. The minimum required fraction of lines before a truncated input is accepted. It is used when image is type Jpeg. Optional\ndctMethod (string) An optional string. Defaults to \"\". string specifying a hint about the algorithm used for decompression. Defaults to \"\" which maps to a system-specific default. Currently valid values are [\"INTEGER_FAST\", \"INTEGER_ACCURATE\"]. The hint may be ignored (e.g., the internal jpeg library changes to a version that does not have that specific option.) It is used when image is type Jpeg. Optional\nReturns: Tensor3D\ntf.node.decodePng (contents, channels?, dtype?) function\nsource\n\nDecode a PNG-encoded image to a 3D Tensor of dtype int32.\n\nParameters:\ncontents (Uint8Array) The PNG-encoded image in an Uint8Array.\nchannels (number) An optional int. Defaults to 0. Accepted values are 0: use the number of channels in the PNG-encoded image. 1: output a grayscale image. 3: output an RGB image. 4: output an RGBA image. Optional\ndtype (string) The data type of the result. Only int32 is supported at this time. Optional\nReturns: Tensor3D\ntf.node.encodeJpeg (image, format?, quality?, progressive?, optimizeSize?, chromaDownsampling?, densityUnit?, xDensity?, yDensity?, xmpMetadata?) function\nsource\n\nEncodes an image tensor to JPEG.\n\nParameters:\nimage (Tensor3D) A 3-D uint8 Tensor of shape [height, width, channels].\nformat (''|'grayscale'|'rgb') An optional string from: \"\", \"grayscale\", \"rgb\". Defaults to \"\". Per pixel image format.\n\n'': Use a default format based on the number of channels in the image.\ngrayscale: Output a grayscale JPEG image. The channels dimension of image must be 1.\nrgb: Output an RGB JPEG image. The channels dimension of image must be 3.\nOptional\nquality (number) An optional int. Defaults to 95. Quality of the compression from 0 to 100 (higher is better and slower). Optional\nprogressive (boolean) An optional bool. Defaults to False. If True, create a JPEG that loads progressively (coarse to fine). Optional\noptimizeSize (boolean) An optional bool. Defaults to False. If True, spend CPU/RAM to reduce size with no quality change. Optional\nchromaDownsampling (boolean) An optional bool. Defaults to True. See http://en.wikipedia.org/wiki/Chroma_subsampling. Optional\ndensityUnit ('in'|'cm') An optional string from: \"in\", \"cm\". Defaults to \"in\". Unit used to specify x_density and y_density: pixels per inch ('in') or centimeter ('cm'). Optional\nxDensity (number) An optional int. Defaults to 300. Horizontal pixels per density unit. Optional\nyDensity (number) An optional int. Defaults to 300. Vertical pixels per density unit. Optional\nxmpMetadata (string) An optional string. Defaults to \"\". If not empty, embed this XMP metadata in the image header. Optional\nReturns: Promise<Uint8Array>\ntf.node.encodePng (image, compression?) function\nsource\n\nEncodes an image tensor to PNG.\n\nParameters:\nimage (Tensor3D) A 3-D uint8 Tensor of shape [height, width, channels].\ncompression (number) An optional int. Defaults to 1. Compression level. Optional\nReturns: Promise<Uint8Array>\nModels\nModels / SavedModel\ntf.node.TFSavedModel extends InferenceModel class\nsource\n\nA tf.TFSavedModel is a signature loaded from a SavedModel metagraph, and allows inference execution.\n\ndispose () method\nsource\n\nDelete the SavedModel from nodeBackend and delete corresponding session in the C++ backend if the session is only used by this TFSavedModel.\n\nReturns: void\npredict (inputs, config?) method\nsource\n\nExecute the inference for the input tensors.\n\nParameters:\ninputs (Tensor|Tensor[]|NamedTensorMap)\nconfig (ModelPredictConfig) Prediction configuration for specifying the batch size. Optional\nReturns: Tensor|Tensor[]|NamedTensorMap\nexecute (inputs, outputs) method\nsource\n\nExecute the inference for the input tensors and return activation values for specified output node names without batching.\n\nParameters:\ninputs (Tensor|Tensor[]|NamedTensorMap)\noutputs (string|string[]) string|string[]. List of output node names to retrieve activation from.\nReturns: Tensor|Tensor[]\ntf.node.getMetaGraphsFromSavedModel (path) function\nsource\n\nInspect the MetaGraphs of the SavedModel from the provided path. This function will return an array of MetaGraphInfo objects.\n\nParameters:\npath (string) Path to SavedModel folder.\nReturns: Promise<MetaGraph[]>\ntf.node.loadSavedModel (path, tags?, signature?) function\nsource\n\nLoad a TensorFlow SavedModel from disk. TensorFlow SavedModel is different from TensorFlow.js model format. A SavedModel is a directory containing serialized signatures and the states needed to run them. The directory has a saved_model.pb (or saved_model.pbtxt) file storing the actual TensorFlow program, or model, and a set of named signatures, each identifying a function. The directory also has a variables directory contains a standard training checkpoint. The directory may also has a assets directory contains files used by the TensorFlow graph, for example text files used to initialize vocabulary tables. These are supported datatypes: float32, int32, complex64, string.For more information, see this guide: https://www.tensorflow.org/guide/saved_model.\n\nParameters:\npath (string) The path to the SavedModel.\ntags ({}) The tags of the MetaGraph to load. The available tags of a SavedModel can be retrieved through tf.node.getMetaGraphsFromSavedModel() API. Defaults to ['serve']. Optional\nsignature (string) The name of the SignatureDef to load. The available SignatureDefs of a SavedModel can be retrieved through tf.node.getMetaGraphsFromSavedModel() API. Defaults to 'serving_default'. Optional\nReturns: Promise<tf.node.TFSavedModel>"
  }
]